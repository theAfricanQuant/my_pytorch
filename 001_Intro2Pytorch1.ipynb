{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd18bf25-bb59-4f3b-98aa-848f8832f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b309080c-9614-449a-9743-32dbb1c320ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0+cu117'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c571c27-f961-48a5-8656-ea2da6cee16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.1+cu117'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d40de2-c044-48ff-929a-7a15a1858cca",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "Tensors in PyTorch are similar to Python lists or NumPy arrays, but they offer some distinct advantages, especially for deep learning. Imagine a tensor as a container that can hold numbers arranged in multiple dimensions - much like a list of lists, but with more capabilities. These multi-dimensional matrices can store elements of the same type, typically numbers.\n",
    "\n",
    "One of the key features of PyTorch tensors is their compatibility with GPUs (Graphics Processing Units). This compatibility allows for faster computations compared to using regular Python lists or NumPy arrays, which are generally limited to CPU (Central Processing Unit) operations. This speed is crucial in deep learning where handling large datasets and complex calculations is common.\n",
    "\n",
    "To illustrate, let's consider a few examples:\n",
    "\n",
    "1. **Single-Dimensional Tensor (1D Tensor):** This is like a regular list or a one-dimensional array. For instance, `[1, 2, 3]` in a tensor form would represent a simple row of numbers.\n",
    "\n",
    "2. **Two-Dimensional Tensor (2D Tensor):** This resembles a matrix or a table with rows and columns. For example, `[[1, 2], [3, 4]]` in tensor form is akin to a 2x2 matrix.\n",
    "\n",
    "3. **Three-Dimensional Tensor (3D Tensor):** You can think of this as a cube of numbers or a list of matrices. An example would be `[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]`, which is like stacking two 2D tensors on top of each other.\n",
    "\n",
    "By default, the numbers in a PyTorch tensor are stored as `float32` type. This means that they are floating-point numbers (numbers with a decimal point) with a precision that balances memory usage and accuracy, making it a common choice for deep learning applications.\n",
    "\n",
    "In summary, tensors in PyTorch are powerful and flexible structures for storing and manipulating numerical data, optimized for performance in large-scale computations typically found in deep learning tasks.\n",
    "\n",
    "### Lists & Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d5da6c-cf6a-4bef-8211-0e3412dd25f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 5, 8], [13, 21, 34, 55, 89]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [[1, 2, 3, 5, 8], [13, 21, 34, 55, 89]]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8072d60c-0a7d-4599-8a27-d25a350dd214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  5,  8],\n",
       "       [13, 21, 34, 55, 89]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list to a NumPy array\n",
    "my_array = np.array(my_list)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e12fcbe7-74db-411f-a89d-ca06ec83ec67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ebfeb9-65c7-457b-949e-7a7a25bf1363",
   "metadata": {},
   "source": [
    "NumPy introduced a new object-oriented approach to generating random numbers in version 1.17. This approach uses the `numpy.random.Generator` class, which provides a wide variety of methods for random number generation. This new paradigm is recommended over the older `numpy.random` functions for several reasons, including improved reproducibility, flexibility, and maintainability of the random number generation process.\n",
    "\n",
    "Here's how you can use this new approach:\n",
    "\n",
    "1. **Creating a Random Number Generator**: First, create a generator object by calling `numpy.random.default_rng()`. This function returns an instance of `numpy.random.Generator`.\n",
    "\n",
    "    ```python\n",
    "    import numpy as np\n",
    "    rng = np.random.default_rng()\n",
    "    ```\n",
    "\n",
    "    The `random()` method in the `numpy.random.Generator` class does not take two arguments for the shape like `rand()`. Instead, it expects a single argument, which is the shape of the output array as a tuple or an integer.\n",
    "   \n",
    "3. **Generating Random Numbers**: Once you have a generator object, you can use its methods to generate random numbers. Here are a few examples:\n",
    "\n",
    "   - **Random Floats**: Generate random floats in the half-open interval [0.0, 1.0).\n",
    "\n",
    "        ```python\n",
    "        random_floats = rng.random(5)  # Array of 5 random floats\n",
    "        print(random_floats)\n",
    "        ```\n",
    "\n",
    "   - **Random Integers**: Generate random integers from low (inclusive) to high (exclusive).\n",
    "\n",
    "        ```python\n",
    "        random_integers = rng.integers(low=1, high=10, size=5)  # 5 random integers between 1 and 9\n",
    "        print(random_integers)\n",
    "        ```\n",
    "\n",
    "   - **Normal Distribution**: Generate numbers from a normal distribution.\n",
    "\n",
    "        ```python\n",
    "        normal_distribution = rng.normal(loc=0, scale=1, size=5)  # 5 numbers from a normal distribution with mean 0 and std 1\n",
    "        print(normal_distribution)\n",
    "        ```\n",
    "\n",
    "   - **Shuffling Arrays**: Randomly shuffle elements of an array.\n",
    "\n",
    "        ```python\n",
    "        arr = np.arange(10)  # Array from 0 to 9\n",
    "        rng.shuffle(arr)  # Shuffle the array\n",
    "        print(arr)\n",
    "        ```\n",
    "\n",
    "4. **Seeding for Reproducibility**: To ensure reproducibility, you can seed the generator.\n",
    "\n",
    "    ```python\n",
    "    rng = np.random.default_rng(seed=43)\n",
    "    repeatable_randoms = rng.random(5)\n",
    "    print(repeatable_randoms)\n",
    "    ```\n",
    "\n",
    "This new OOP-based approach is more powerful and flexible and is now the preferred method for generating random numbers in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19af358b-c112-4cff-8bdf-824d7e9520f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65229926, 0.04377532, 0.02002959, 0.83921258, 0.58714305],\n",
       "       [0.22470523, 0.75179227, 0.2636922 , 0.41997791, 0.45103139],\n",
       "       [0.95531458, 0.89190167, 0.27863303, 0.2785343 , 0.42199957]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=43)\n",
    "rand_floats = rng.random((3, 5))  \n",
    "rand_floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e564afb-39fe-42d7-9787-7928035b6506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_floats.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1502e0-fb7f-4ded-bf21-8721bc09ae7f",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f0d0931-de47-492b-bfbb-b4ac8cb96516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4540, 0.1965, 0.9210, 0.3462, 0.1481],\n",
       "        [0.0858, 0.5909, 0.0659, 0.7476, 0.6253],\n",
       "        [0.9392, 0.1338, 0.5191, 0.5335, 0.5375]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(43)\n",
    "\n",
    "# Create a 3x5 tensor with random values\n",
    "tensor_3x5 = torch.rand(3, 5)\n",
    "tensor_3x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da5e6fb4-f556-47a5-8a43-3582720eba9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_3x5.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a457d475-0d3b-4276-b348-214085793ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  5,  8],\n",
       "        [13, 21, 34, 55, 89]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensors out of numpy arrays\n",
    "my_tensor = torch.tensor(my_array)\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84d51d66-0944-457b-b54b-636e7ead0d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81fa40e-c651-40ef-b595-43b090fabef0",
   "metadata": {},
   "source": [
    "The `dtype` above is definitely because that was from the numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4ec9095-fcc8-4147-ae2b-1d7610ff56a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6523, 0.0438, 0.0200, 0.8392, 0.5871],\n",
       "        [0.2247, 0.7518, 0.2637, 0.4200, 0.4510],\n",
       "        [0.9553, 0.8919, 0.2786, 0.2785, 0.4220]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tensors = torch.tensor(rand_floats)\n",
    "rand_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e39499-6e5c-40e7-9765-9e718c7a17a3",
   "metadata": {},
   "source": [
    "### Tensor Operations\n",
    "\n",
    "Tensor reshaping in PyTorch is a crucial operation that allows you to rearrange the elements of a tensor to a new shape without changing the underlying data. This functionality is essential in various deep learning scenarios, such as feeding data into a model or altering the output format. PyTorch provides several methods to reshape tensors, the most common being `view()` and `reshape()`.\r\n",
    "\r\n",
    "### How to Perform Reshaping\r\n",
    "\r\n",
    "1. **Using `view()`**:\r\n",
    "   - `view()` returns a new tensor with the same data as the original tensor but of a different shape.\r\n",
    "   - The new shape must have the same number of elements as the original shape.\r\n",
    "   - Example:\r\n",
    "     ```python\r\n",
    "     import torch\r\n",
    "     x = torch.randn(4, 4)\r\n",
    "     y = x.view(16)  # Reshape to a 1D tensor of 16 elements\r\n",
    "     z = x.view(-1, 8)  # Reshape to a 2D tensor; one dimension inferred\r\n",
    "     ```\r\n",
    "\r\n",
    "2. **Using `reshape()`**:\r\n",
    "   - `reshape()` works similarly to `view()` but can handle some additional cases, like memory layout changes.\r\n",
    "   - It returns a tensor with the same data but potentially in a different memory layout, making it more flexible but potentially less efficient.\r\n",
    "   - Example:\r\n",
    "     ```python\r\n",
    "     y = x.reshape(16)\r\n",
    "     z = x.reshape(-1, 8)\r\n",
    "     ```\r\n",
    "\r\n",
    "### Pitfalls to Avoid\r\n",
    "\r\n",
    "1. **Contiguity Issue with `view()`**:\r\n",
    "   - `view()` requires the base tensor to be contiguous in memory. If it's not, you might need to call `contiguous()` before `view()`.\r\n",
    "   - Non-contiguous tensors can occur after operations like `transpose()`, `narrow()`, `expand()`, etc.\r\n",
    "   - Example:\r\n",
    "     ```python\r\n",
    "     x = x.transpose(0, 1)\r\n",
    "     y = x.view(16)  # This will raise an error\r\n",
    "     y = x.contiguous().view(16)  # Correct approach\r\n",
    "     ```\r\n",
    "\r\n",
    "2. **Matching the Number of Elements**:\r\n",
    "   - Ensure the new shape has the same total number of elements as the original shape. Mismatching element counts will result in an error.\r\n",
    "\r\n",
    "### Use Case Scenarios\r\n",
    "\r\n",
    "1. **Feeding Data into a Model**:\r\n",
    "   - When using neural networks, input data often need to be reshaped. For instance, you might need to flatten images into a 1D tensor before feeding them into a fully connected layer.\r\n",
    "\r\n",
    "2. **Altering Output Format**:\r\n",
    "   - After a model generates output, you might need to reshape this output to a desired format for further processing or evaluation.\r\n",
    "\r\n",
    "3. **Batch Processing**:\r\n",
    "   - When dealing with batches of data, you may need to reshape tensors to align with batch dimensions expected by your model.\r\n",
    "\r\n",
    "4. **Dimension Permutation**:\r\n",
    "   - In some cases, such as when dealing with convolutional neural networks, you might need to permute the dimensions of a tensor (e.g., changing a tensor shape from `[batch_size, height, width, channels]` to `[batch_size, channels, height, width]`).\r\n",
    "\r\n",
    "Remember, reshaping tensors does not involve changing the underlying data itself, but rather how it's interpreted or accessed. This makes reshaping a fast operation, as it doesn't require modifying the data in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85776aee-b72c-4aac-b33c-306ab9bef8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch = torch.arange(10)\n",
    "my_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3833d504-2010-4d95-93b3-840db09082a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape and View\n",
    "my_torch = my_torch.reshape(2, 5)\n",
    "my_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a77a93-76da-4fc7-bdc8-43566acbabf6",
   "metadata": {},
   "source": [
    "In PyTorch, using `-1` as a dimension in reshaping operations like `view()` or `reshape()` is a convenience feature that allows you to flexibly specify the tensor's shape without explicitly computing one of its dimensions. When you use `-1`, PyTorch automatically calculates the appropriate size for that dimension based on the tensor's total number of elements and the other specified dimensions.\n",
    "\n",
    "### Why It's Useful:\n",
    "\n",
    "1. **Flexibility**: It lets you reshape tensors without needing to explicitly calculate every dimension. This is particularly useful when you know the size of all but one dimension.\n",
    "\n",
    "2. **Maintaining Total Number of Elements**: It ensures that the reshaping operation maintains the total number of elements in the tensor. PyTorch calculates the missing dimension such that the product of the dimensions of the reshaped tensor equals the product of the dimensions of the original tensor.\n",
    "\n",
    "3. **Readability and Maintenance**: It makes your code more readable and easier to maintain, especially when dealing with tensors whose size might change, such as different batch sizes in neural network training.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Suppose you have a tensor of shape `(4, 4)` and you want to reshape it into a 2D tensor where one dimension is 8. You might not know (or want to calculate) what the other dimension should be. Here's where `-1` comes in handy:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(-1, 8)  # Reshapes x to a shape that has 8 columns and the appropriate number of rows\n",
    "```\n",
    "\n",
    "In this example, `y` will have a shape of `(2, 8)`. PyTorch figures out that since the original tensor has 16 elements (4 * 4), and one of the dimensions in the new shape is 8, the other must be 2 in order to keep the total number of elements the same.\n",
    "\n",
    "### Caveats:\n",
    "\n",
    "- You can only use `-1` for one dimension. If you use it for multiple dimensions, PyTorch won't be able to infer the correct shapes.\n",
    "- The original tensor's total number of elements must be divisible by the product of the specified dimensions for the operation to be valid. If it's not, you'll get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62aab2bc-7270-4059-8534-155659ea07ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4540],\n",
       "        [0.1965],\n",
       "        [0.9210],\n",
       "        [0.3462],\n",
       "        [0.1481],\n",
       "        [0.0858],\n",
       "        [0.5909],\n",
       "        [0.0659],\n",
       "        [0.7476],\n",
       "        [0.6253],\n",
       "        [0.9392],\n",
       "        [0.1338],\n",
       "        [0.5191],\n",
       "        [0.5335],\n",
       "        [0.5375]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_reshape = tensor_3x5.reshape(15, -1)\n",
    "tensor_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b1e151a-ff65-4ccb-b659-509c88b8064b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch1 = torch.arange(10)\n",
    "my_torch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b989b67-2f12-4477-bab2-b1eb7e771208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.reshape(2, -1)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94693b1c-46c3-49c9-a677-4ae7458dfc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.reshape(-1, 2)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffeab13d-1b60-4e79-abee-3fea04732a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch1 = torch.arange(20)\n",
    "my_torch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14114d5b-4f0d-4d4a-87f1-f6a8455861db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 2,  3],\n",
       "        [ 4,  5],\n",
       "        [ 6,  7],\n",
       "        [ 8,  9],\n",
       "        [10, 11],\n",
       "        [12, 13],\n",
       "        [14, 15],\n",
       "        [16, 17],\n",
       "        [18, 19]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.reshape(-1, 2)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50489f93-3199-41fd-b68c-1f88fa48db18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.reshape(-1, 4)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9be98633-a8fc-46f2-ae92-dde992224d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.reshape(5, -1)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d526f241-3c3f-4a05-86f5-ab66d27debdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.reshape(4, -1)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "734bcb4e-1fc4-4583-9f29-84056fcc63a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.reshape(2, -1)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "011f6d74-68c3-46d8-9740-cf5b46610307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch1 = torch.arange(20)\n",
    "my_torch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b1af0a0-4052-43c0-ba1b-70747b520d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.view(2, -1)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0da49a6-67ee-4858-8496-0647147609c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.view(4, -1)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "690600d2-d465-4873-b9f4-e56169e2ddea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch2 = my_torch1.view(5, -1)\n",
    "my_torch2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f667b66-e31f-4539-bb2c-5acefaa899aa",
   "metadata": {},
   "source": [
    "### Understanding Contiguous Tensors\n",
    "\n",
    "Firstly, a tensor is \"contiguous\" in memory when its elements are stored in an uninterrupted block of memory. In simple terms, contiguous storage means the way the elements are laid out in memory matches the order in which they are accessed.\n",
    "\n",
    "For instance, if you transpose a tensor, the logical order of its elements changes, but their actual order in memory doesn't. This can lead to a non-contiguous tensor.\n",
    "\n",
    "### `torch.view`\n",
    "\n",
    "- `torch.view` is used to reshape a tensor without changing its data.\n",
    "- It requires the tensor to be contiguous because it doesn't rearrange memory, it just changes the view of the original tensor.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Contiguous Tensor\n",
    "x = torch.arange(10)  # Tensor from 0 to 9\n",
    "x_view = x.view(2, 5)  # Reshaping to a 2x5 tensor\n",
    "print(x_view)\n",
    "\n",
    "# After an operation like transpose, the tensor becomes non-contiguous\n",
    "y = x_view.t()  # Transpose\n",
    "try:\n",
    "    y.view(10)  # This will fail because y is not contiguous\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "# Making it contiguous before reshaping\n",
    "y_contiguous = y.contiguous()\n",
    "y_view = y_contiguous.view(10)  # This works\n",
    "print(y_view)\n",
    "```\n",
    "\n",
    "### `torch.reshape`\n",
    "\n",
    "- `torch.reshape` is more flexible and can handle both contiguous and non-contiguous tensors.\n",
    "- It returns a tensor with the desired shape, rearranging the memory if necessary.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "# Using the same transposed tensor\n",
    "y_reshaped = y.reshape(10)  # Works even if y is non-contiguous\n",
    "print(y_reshaped)\n",
    "```\n",
    "\n",
    "### Summary:\n",
    "\n",
    "- **Contiguous Tensor (`torch.view`)**: Use `view` when you have a contiguous tensor and want a quick, memory-efficient reshaping.\n",
    "  \n",
    "- **Non-Contiguous Tensor (`torch.reshape`)**: If you're not sure whether your tensor is contiguous, or you've performed operations like transpose, use `reshape`. It's safer as it handles both contiguous and non-contiguous tensors, though it may involve a memory copy in non-contiguous cases, making it slightly less efficient.\n",
    "\n",
    "Understanding the memory layout and ensuring efficient operations are crucial in deep learning tasks where performance and memory usage are often critical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40628c42-ca1c-47fb-999d-5bcb48c70a2e",
   "metadata": {},
   "source": [
    "Certainly! Let's use a simpler analogy to understand what \"contiguous\" means in the context of tensors and memory.\n",
    "\n",
    "### Analogy: A Bookshelf\n",
    "\n",
    "Imagine you have a bookshelf where each slot can hold one book, and you have a series of books numbered from 1 to 10.\n",
    "\n",
    "- **Contiguous Placement**: If you place these books in order, from left to right, without any gaps in between, this is like having a contiguous tensor. When you reach for book 1, you know that book 2 is right next to it, followed by 3, and so on. In memory, a contiguous tensor stores its elements in this uninterrupted, sequential manner.\n",
    "\n",
    "- **Non-Contiguous Placement**: Now, suppose you take out these books and put them back on the shelf, but this time you alternate the slots. You place book 1 in the first slot, skip the second slot, place book 2 in the third slot, and so on. Visually, the order is still 1, 2, 3, etc., but there are gaps between the books. This is like having a non-contiguous tensor. The elements (books) are logically in order, but they're not stored sequentially in memory (on the shelf).\n",
    "\n",
    "### Applying the Analogy to Tensors\n",
    "\n",
    "When you perform certain operations on a tensor, like transposing, you change how you access its elements without moving them around in memory. It's like saying, \"Now I want to read the books in reverse order,\" but without physically rearranging them on the shelf. After such operations, the tensor becomes non-contiguous because the order in which you access its elements doesn't match their actual order in memory.\n",
    "\n",
    "Operations like `torch.view` rely on the elements being stored contiguously. They just change your perspective (or view) of the tensor, not the actual order of elements in memory. If the tensor is non-contiguous, `torch.view` can't be used directly because it expects elements to be in a sequential order in memory.\n",
    "\n",
    "In contrast, `torch.reshape` can handle non-contiguous tensors. It's like saying, \"I want these books in a specific order, and if they are not in that order on the shelf, I'll rearrange them to make it so.\" This flexibility means that `reshape` can be used in more scenarios but might require actually moving data around in memory, which can be less efficient.\n",
    "\n",
    "The issue of tensors being contiguous or not matters primarily for performance reasons. Understanding and managing the contiguity of tensors is crucial in optimizing computational efficiency, especially in memory-intensive applications like deep learning and scientific computing. Let's delve into why this is important and consider another package where this concept is relevant.\r\n",
    "\r\n",
    "### Why Contiguity Matters:\r\n",
    "\r\n",
    "1. **Memory Access Patterns**: In contiguous tensors, elements are laid out sequentially in memory. This allows for efficient memory access and vectorized operations, which are faster due to modern CPU and GPU architectures favoring sequential memory access.\r\n",
    "\r\n",
    "2. **Performance Optimization**: Many underlying libraries and hardware accelerators perform best with contiguous memory layouts. Non-contiguous tensors can lead to more complex memory access patterns, potentially slowing down computations.\r\n",
    "\r\n",
    "3. **Function Compatibility**: Certain operations expect tensors to be contiguous. For instance, in PyTorch, the `view()` function requires tensors to be contiguous. If a tensor is non-contiguous, operations may either fail or implicitly make a contiguous copy of the tensor, which can add overhead.\r\n",
    "\r\n",
    "4. **Memory Efficiency**: Non-contiguous tensors can lead to fragmented memory usage, making less efficient use of available memory resources.\r\n",
    "\r\n",
    "### Another Package: NumPy\r\n",
    "\r\n",
    "NumPy, a popular Python library for numerical computing, also considers tensor (array) contiguity:\r\n",
    "\r\n",
    "- **Memory Layout**: Like PyTorch, NumPy stores array elements in contiguous blocks of memory by default. However, operations like `transpose` can result in non-contiguous arrays.\r\n",
    "\r\n",
    "- **Strides**: NumPy uses the concept of \"strides\" to determine how to traverse an array. A non-contiguous array in NumPy may have strides that skip over memory locations, similar to the non-contiguous tensors in PyTorch.\r\n",
    "\r\n",
    "- **Performance**: In NumPy, functions may perform differently based on whether an array is contiguous. For example, functions from libraries like SciPy or operations involving C extensions might require contiguous arrays for optimal performance.\r\n",
    "\r\n",
    "- **Manipulation Functions**: NumPy provides functions like `np.copy()` and `np.ascontiguousarray()` to handle non-contiguous arrays and ensure they are contiguous, which is similar to calling `.contiguous()` in PyTorch.\r\n",
    "\r\n",
    "### Conclusion\r\n",
    "\r\n",
    "The concept of contiguity is not unique to PyTorch but is a common consideration in many high-performance computing libraries, including NumPy. It's a crucial aspect for efficiency in processing large-scale numerical data, which is why both NumPy and PyTorch provide tools and functions to manage and optimize memory layout. Understanding and properly managing tensor contiguity can significantly impact the performance and efficiency of your numerical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0014571-cf90-4ff5-8b47-868618c9b544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_torch3 = torch.arange(25)\n",
    "my_torch3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b703d2dc-f701-453b-a145-73f4b3a0163a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape the tensor\n",
    "my_torch4 = my_torch3.reshape(5, -1)\n",
    "my_torch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "105db22c-f433-442c-bc2d-9123254dabb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16, 999,  18,  19,  20,  21,  22,  23,  24])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's change the 17th element to 43 from the my_torch3\n",
    "my_torch3[17]=999\n",
    "my_torch3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2558ab1-1949-46ab-895c-d3a0bc5e489b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9],\n",
       "        [ 10,  11,  12,  13,  14],\n",
       "        [ 15,  16, 999,  18,  19],\n",
       "        [ 20,  21,  22,  23,  24]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see if the 17th element in the my_torch4 is also changed\n",
    "my_torch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0cf1f8d6-9ee0-46da-b752-c0dc6db4889c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the 21st item from my_torch3\n",
    "my_torch3[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5da15fe-0360-43fa-9233-889098c671eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  8, 13, 18, 23])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab a slice from my_torch4 ie the 3rd column\n",
    "my_torch4[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51b2a800-8cb3-48dd-b977-581423889ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [ 8],\n",
       "        [13],\n",
       "        [18],\n",
       "        [23]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab a slice from my_torch4 ie the 3rd column\n",
    "my_torch4[:, 3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bffef4d8-1678-49a0-9b39-bcefb69d5fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2,   3,   4],\n",
       "        [  7,   8,   9],\n",
       "        [ 12,  13,  14],\n",
       "        [999,  18,  19],\n",
       "        [ 22,  23,  24]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab a slice from my_torch4 multiple columns\n",
    "my_torch4[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "07cd69e9-b58b-4d90-a055-581036207b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 15,  16, 999,  18,  19])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab a slice from my_torch4 multiple rows\n",
    "my_torch4[3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a4bca-9ccc-4dd0-a0e2-d7d80e35a779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
